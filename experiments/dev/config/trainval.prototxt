model {
  attention_recognition_model {
    feature_extractor {
      baseline_feature_extractor {
      }
    }

    predictor {
      bahdanau_attention_predictor {
        rnn_cell {
          gru_cell {
            num_units: 256
          }
        }
        num_attention_units: 256
        max_num_steps: 30
      }
    }

    label_map {
      character_set {
        text_string: "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ"
        delimiter: ""
      }
    }
    
    loss {
      sequence_cross_entropy_loss {
        sequence_normalize: true
        sample_normalize: true
      }
    }
  }
}

train_config {
  batch_size: 128
  optimizer {
    adam_optimizer {
      learning_rate {
        manual_step_learning_rate {
          initial_learning_rate: 1e-2
          schedule {
            step: 60000
            learning_rate: 1e-4
          }
          schedule {
            step: 75000
            learning_rate: 1e-5
          }
        }
      }
    }
  }
  num_steps: 90000
  data_augmentation_options {
    resize_image_random_method {
      target_height: 32
      target_width: 128
    }
  }
  data_augmentation_options {
    string_filtering {
      lower_case: true
      include_charset: "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ"
    }
  }
}

train_input_reader {
  tf_record_input_reader {
    input_path: "data/synth90k_all.tfrecord"
  }
}

eval_config: {
  metrics_set: "recognition_metrics"
  num_examples: 500
  data_preprocessing_steps {
    resize_image {
      target_width: 128
      target_height: 32
    }
  }
  num_visualizations: 0
  visualization_export_dir: ""
}

eval_input_reader: {
  num_epochs: 1
  num_readers: 1
  shuffle: false

  tf_record_input_reader {
    input_path: "data/synth90k_10k.tfrecord"
  }
}
